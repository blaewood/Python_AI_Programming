{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "프로그램 4-4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMY9rhAacM0Vqvo8YyEMkc4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/blaewood/Python_AI_Programming/blob/main/%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%A8_4_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ModPDzF-2efa",
        "outputId": "3888afe9-e2d8-463f-893a-b7b30ac35eca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1, loss = 0.61117147\n",
            "Iteration 2, loss = 0.25997720\n",
            "Iteration 3, loss = 0.20524487\n",
            "Iteration 4, loss = 0.17110896\n",
            "Iteration 5, loss = 0.14794567\n",
            "Iteration 6, loss = 0.13083715\n",
            "Iteration 7, loss = 0.11668538\n",
            "Iteration 8, loss = 0.10485049\n",
            "Iteration 9, loss = 0.09562668\n",
            "Iteration 10, loss = 0.08655475\n",
            "Iteration 11, loss = 0.07970786\n",
            "Iteration 12, loss = 0.07295932\n",
            "Iteration 13, loss = 0.06730426\n",
            "Iteration 14, loss = 0.06203187\n",
            "Iteration 15, loss = 0.05708730\n",
            "Iteration 16, loss = 0.05372210\n",
            "Iteration 17, loss = 0.04957390\n",
            "Iteration 18, loss = 0.04597581\n",
            "Iteration 19, loss = 0.04240688\n",
            "Iteration 20, loss = 0.03951601\n",
            "Iteration 21, loss = 0.03665983\n",
            "Iteration 22, loss = 0.03463732\n",
            "Iteration 23, loss = 0.03211872\n",
            "Iteration 24, loss = 0.03041462\n",
            "Iteration 25, loss = 0.02815806\n",
            "Iteration 26, loss = 0.02603128\n",
            "Iteration 27, loss = 0.02415864\n",
            "Iteration 28, loss = 0.02264526\n",
            "Iteration 29, loss = 0.02131254\n",
            "Iteration 30, loss = 0.02007489\n",
            "Iteration 31, loss = 0.01821230\n",
            "Iteration 32, loss = 0.01759850\n",
            "Iteration 33, loss = 0.01596873\n",
            "Iteration 34, loss = 0.01564681\n",
            "Iteration 35, loss = 0.01410202\n",
            "Iteration 36, loss = 0.01288241\n",
            "Iteration 37, loss = 0.01242497\n",
            "Iteration 38, loss = 0.01142842\n",
            "Iteration 39, loss = 0.01080307\n",
            "Iteration 40, loss = 0.01004301\n",
            "Iteration 41, loss = 0.00940648\n",
            "Iteration 42, loss = 0.00834797\n",
            "Iteration 43, loss = 0.00795253\n",
            "Iteration 44, loss = 0.00759667\n",
            "Iteration 45, loss = 0.00721872\n",
            "Iteration 46, loss = 0.00688348\n",
            "Iteration 47, loss = 0.00618909\n",
            "Iteration 48, loss = 0.00578124\n",
            "Iteration 49, loss = 0.00549945\n",
            "Iteration 50, loss = 0.00494024\n",
            "Iteration 51, loss = 0.00464277\n",
            "Iteration 52, loss = 0.00443264\n",
            "Iteration 53, loss = 0.00401147\n",
            "Iteration 54, loss = 0.00378256\n",
            "Iteration 55, loss = 0.00354148\n",
            "Iteration 56, loss = 0.00325540\n",
            "Iteration 57, loss = 0.00320137\n",
            "Iteration 58, loss = 0.00293350\n",
            "Iteration 59, loss = 0.00272422\n",
            "Iteration 60, loss = 0.00256591\n",
            "Iteration 61, loss = 0.00239643\n",
            "Iteration 62, loss = 0.00232266\n",
            "Iteration 63, loss = 0.00215780\n",
            "Iteration 64, loss = 0.00203216\n",
            "Iteration 65, loss = 0.00193440\n",
            "Iteration 66, loss = 0.00181838\n",
            "Iteration 67, loss = 0.00175632\n",
            "Iteration 68, loss = 0.00161098\n",
            "Iteration 69, loss = 0.00155190\n",
            "Iteration 70, loss = 0.00146101\n",
            "Iteration 71, loss = 0.00139093\n",
            "Iteration 72, loss = 0.00129425\n",
            "Iteration 73, loss = 0.00125534\n",
            "Iteration 74, loss = 0.00118752\n",
            "Iteration 75, loss = 0.00113654\n",
            "Iteration 76, loss = 0.00111271\n",
            "Iteration 77, loss = 0.00102046\n",
            "Iteration 78, loss = 0.00099134\n",
            "Iteration 79, loss = 0.00091577\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "[[ 971    0    4    1    1    3    6    1    3    4]\n",
            " [   0 1124    0    0    0    0    2    4    1    2]\n",
            " [   1    3 1001    3    3    0    3    9    4    0]\n",
            " [   2    1    7  988    1    7    1    4    6    6]\n",
            " [   0    0    3    1  963    2    4    0    4   10]\n",
            " [   1    1    0    4    0  873    6    1    4    3]\n",
            " [   3    2    3    1    4    2  933    0    1    0]\n",
            " [   0    1    6    6    1    0    0 1004    4    2]\n",
            " [   2    3    7    3    2    3    3    2  943    5]\n",
            " [   0    0    1    3    7    2    0    3    4  977]]\n",
            "테스트 집합에 대한 정확률은 97.77 %입니다.\n"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# MNIST 데이터셋을 읽고 훈련 집합과 테스트 집합으로 분할\n",
        "mnist=fetch_openml('mnist_784')\n",
        "mnist.data=mnist.data/255.0\n",
        "x_train=mnist.data[:60000]; x_test=mnist.data[60000:]\n",
        "y_train=np.int16(mnist.target[:60000]); y_test=np.int16(mnist.target[60000:])\n",
        "\n",
        "# MLP 분류기 모델을 학습\n",
        "mlp=MLPClassifier(hidden_layer_sizes=(100),learning_rate_init=0.001,batch_size=512,max_iter=300,solver='adam',verbose=True)\n",
        "mlp.fit(x_train,y_train)\n",
        "\n",
        "# 테스트 집합으로 예측\n",
        "res=mlp.predict(x_test)\n",
        "\n",
        "# 혼동 행렬\n",
        "conf=np.zeros((10,10),dtype=np.int16)\n",
        "for i in range(len(res)):\n",
        "    conf[res[i]][y_test[i]]+=1\n",
        "print(conf)\n",
        "\n",
        "# 정확률 계산\n",
        "no_correct=0\n",
        "for i in range(10):\n",
        "    no_correct+=conf[i][i]\n",
        "accuracy=no_correct/len(res)\n",
        "print(\"테스트 집합에 대한 정확률은\", accuracy*100, \"%입니다.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "wv7DwAxH2vGf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}